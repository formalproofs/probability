import Probability.Probability.Prelude

import Probability.Probability.Defs
import Mathlib.Data.Matrix.Mul
import Mathlib.LinearAlgebra.Matrix.DotProduct

namespace Matrix

section ProbabilityMatrix

structure ProbabilityMatrix (n : ‚Ñï) : Type where
    --(n x n) Matrix where each row is a probability distribution
    P : (Matrix (Fin n) (Fin n) ‚Ñö)
    row_sum : P *·µ• 1 = 1
    nneg : ‚àÄ i j : Fin n, P i j ‚â• 0

variable (n : ‚Ñï) (Prob : ProbabilityMatrix n) (Œº : Findist n) (r : Fin n ‚Üí ‚Ñö) (Œ≥ : ‚Ñö)


theorem dist_prob_product_nneg : Œº.p ·µ•* (Prob.P) ‚â• 0 := by
    unfold vecMul
    intro j
    apply dotProduct_nonneg_of_nonneg
    exact Œº.nneg
    exact fun i => Prob.nneg i j

theorem dist_prob_product_sum : Œº.p ·µ•* (Prob.P) ‚¨ù·µ• 1 = 1 := by
    rw [‚Üê dotProduct_mulVec]
    calc Œº.p ‚¨ù·µ• Prob.P *·µ• 1 = Œº.p ‚¨ù·µ• 1 := by rw[Prob.row_sum]
        _ = 1 ‚¨ù·µ• Œº.p := by rw[dotProduct_comm]
        _ = 1 := by rw[Œº.prob]

end ProbabilityMatrix

section RewardProcess

--Discounted Markov Reward Process Definition
structure DMRP (n : ‚Ñï) : Type where
    r : Fin n ‚Üí ‚Ñö --rewards
    Prob : ProbabilityMatrix n --transitions
    Œ≥ : ‚Ñö --discount
    discount_in_range : 0 ‚â§ Œ≥ ‚àß Œ≥ < 1

variable (n : ‚Ñï) (Proc : DMRP n) (u : (Fin n) ‚Üí ‚Ñö) (v : (Fin n) ‚Üí ‚Ñö)

def bellman_backup (v : Fin n ‚Üí ‚Ñö) : Fin n ‚Üí ‚Ñö := Proc.r + Proc.Œ≥ ‚Ä¢ Proc.Prob.P *·µ• v

notation "ùîπ["v "//" Proc "]" => bellman_backup Proc v

-- Looking for norm in mathlib
theorem bellman_backup_contraction : 1 = 1 := by sorry

end RewardProcess
